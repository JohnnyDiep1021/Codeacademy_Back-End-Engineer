PostgreSQL Roles: Database Security

Permission Name: SUPERUSER, CREATEROLE, CREATEDB, LOGIN, IN ROLE

NOSUPERUSER is the default behavior when no option is specified.
database default role name with SUPERUSER privileges: postgres

Schema level permissions: 
USAGE: allow a role to access tables within that schema
CREATE, DROP: allow the grantee the ability to create or remove tables in that schema respectively.

SELECT current_user => Get current role in use
SELECT grantor, grantee, table_schema, table_name, privilege_type FROM information_schema.table_privileges
=> description of the permissions a user (grantee) has on a table.
SELECT rolname FROM pg_catalog.pg_roles; => listing all user roles in the database

CREATE ROLE <rolname> WITH <Permission Name> => Superuser can create new roles
SET ROLE <rolname> => regain a specific role privileges 
ALTER ROLE <rolname> WITH <Permission Name> => give "rolname" with new permission
GRANT/ REVOKE <permission1, permission2, ...> ON SCHEMA <schemaname> TO/FROM <rolname> 
=> grant/revoke specific permissions on a specific schema
GRANT/ REVOKE <permission1, permission2, ...> ON <schemaname.tablename/ tablename> TO/FROM <rolname>
=> grant/revoke specific permissions on a specific table in a schema

With default permissions, a superuser can set permissions to be updated automatically 
when new objects are created in a schema. Default permissions only apply to objects created after 
the defaults are set

GRANT <permissions> ON <schemaname> TO <rolname>;
GRANT <permissions> ON ALL TABLES IN <schemaname> TO <rolname>;
ALTER DEFAULT PRIVILEGES IN SCHEMA <schemaname>/ IN DATABASE <database name> GRANT SELECT ON TABLES TO analyst;

Groups role and Inheritance
As members of a group role, as members, these roles will inherit certain permissions from that group. 
For security reasons, PostgreSQL disallows the inheritance of certain powerful permissions such as 
LOGIN, SUPERUSER, CREATEDB, and CREATEROLE. This prevents a developer from 
accidentally granting high-level permissions to a wide group of users.

CREATE ROLE <grouprolname> WITH <permissions> IN ROLE <memberrolname> 
=> add users roles to group(s) roles on creation

GRANT <rolname> TO <listofrolname> => grants all the permissions of the newly created role to the listed names.

Column Level Security

GRANT <permissions> (<col1>, <col2>, etc.) ON <tablename> to <rolname>;
=> grant permissions to rolname on specific columns

Row Level Security
Allows developers to define permissions on individual rows. 

CREATE POLICY <policyname> ON <tablename> FOR <permissions> TO <rolname> USING (conditions)
e.g: conditions => USING (colname=current_user) 

ALTER TABLE <tablename> ENABLE ROW LEVEL SECURITY; => enable RLS on the table the policy refers to.

Introduction to Indexes
An index is an organization of the data in a table to help with performance when searching and filtering records. 
A table can have zero, one, or many indexes. There are some costs when using indexes, which we will cover later 
in this lesson.

SELECT * FROM pg_Indexes WHERE tablename='tablename'; =>  see what indexes exist on tables
pg_Indexes is a built-in view in PostgreSQL. Different database servers have different ways to see their indexes.

Benefits of an Index
Indexing allows you to organize your database structure in such a way that it makes finding specific records 
much faster. By default it divides the possible matching records in half, then half, then half, and
so on until the specific match you are searching for is found. This is known as a Binary Tree, or B-Tree.
In order to see the benefits of an index, a large database is required.

Increase in speed of searches/filtering
Increase in storage space
Increase in runtime for Insert/Update/Delete on impacted indexes.

Impact of Indexes
filtering data

To get insight into how PostgreSQL breaks down your statements into runnable parts, 
we can investigate the query plan by adding EXPLAIN ANALYZE
e.g EXPLAIN ANALYZE SELECT * FROM customers WHERE first_name='David';

If you see “Seq Scan” this means that the system is scanning every record to find the specific records 
you are looking for. If you see “Index” (in our examples more specifically “Bitmap Index Scan”) you know 
that the server is taking advantage of an index to improve the speed of your search.

The planning time is the amount of time the server spends deciding the best way to solve your query, should 
it use an index, or do a full scan of the table(s) for instance. The execution time is the amount of time the 
actual query takes to run after the server has decided on a plan of attack.

CREATE INDEX [UNIQUE] <indexname> ON <tablename> (exp(colname1, colname2, etc.))
Creating indexes comes at the cost of increased runtime for any modification (insert, update, etc.) to the table 
data impacting the user_name column. Another cost is the space that the index takes up.
A multicolumn index referred to by other names as well, such as Composite or Compound.

Conventional index naming pattern: tablename_colnames_idx

DROP INDEX IF EXISTS <idxname>

Index filtering
building indexes will be used for filtering data quickly. If an index is created on the columns referenced in 
these clauses, the database server will examine the index to see if it will improve the speed of the query.
The index is built in the specific order listed at creation. The order will impact the efficiency of your searches.

Recall that at its core, an index is an organization of the data in a table. When new data is added, the index 
will be reshaped to fit that new data into its organization. This means that when you write a single statement 
to modify the records, the server will have to modify every index that would be impacted by this change. If you are 
adding a large amount of data to an existing table, it may be better to drop the index, add the data, and then 
recreate the index rather than having to update the index on each insertion.

If you have multiple indexes on a single table and you insert a record, you will need to update each 
index associated with the table. This can make indexes very costly.

Updates and deletes have similar drawbacks. When deleting a record that is associated with an index, it 
might be faster to find the record — by leveraging the index’s ability to search. However, once the record is 
found, removing or editing it will result in the same issue as inserting a new record. The index itself will need 
to be redone. Note that if you’re updating a non-indexed column, that update will be unaffected by the index. So 
if you are updating a non-indexed column while filtering by one with an index, an update statement can actually be 
faster with an index.

When should an index be added?
The simple answer is when the benefits of searching outweigh the burdens of storage size and 
Insert/Update/Delete speed. One thing to consider is whether searching will occur often enough to make 
the advantages worth the time and effort.

Partial Index
A partial index allows for indexing on a subset of a table, allowing searches to be conducted on just this group of 
records in the table. Notice that the filtering of the index does not have to be for a column that is part of your index.

CREATE INDEX <idxname> ON <tblname> (<colnames>)
WHERE conditions;

Order by
If you are commonly ordering your data in a specific way on an indexed column, you can add this information to the 
index itself and PostgreSQL will store the data in your desired order.

CREATE INDEX <idxname> ON <tblname> (<colnames> [DESC/ ASC/ NULL FIRST/ NULL LAST])

A unique index, primary key, and unique constraint all reject any attempt to have two records in a table that would 
have the same value (multicolumns versions of these would reject any record where all the columns are equal).
As a note, the primary key index standard is to end in _pkey instead of _idx to identify it as a specific type of index. 
It is also the way the system names it when created automatically.

Clustered Index
We learned in the previous lesson that an index is an organization of the data in a table. A table can have many indexes. 
To expand on this, all indexes are either a clustered index or a non-clustered index.
- A clustered index is often tied to the table’s primary key.
- When a clustered index is created for a table, the data is physically organized in the table structure to allow 
for improved search times. 
- Clustered index like searching a dictionary.
- There can only be one clustered index per table.

When the system creates, alters, or refreshes a clustered index, it takes all the records in your database table 
that are in memory and rearranges them to match the order of your clustered index, physically altering their location 
in storage

CLUSTER <tblname> USING <idxname>; => cluster database table using an existing index
CLUSTER <tblname>; => recluster database table
CLUSTER; => cluster every table that has an identified index to use

Non-Clustered Index
You can create many indexes on a table, but only one can be a clustered index, so what about the rest? They are known as 
non-clustered indexes
Non-clustered indexes have records of the columns they are indexing and a pointer back to the actual data in the table 
When you search on a non-clustered index for more information than is in the indexed columns, there are two searches. 
The first to find the record in the index and another to find the record the pointer identifies.

Recap:
A clustered index contains all the information in your table and physically reorganizes the way it is stored in memory. 
A non-clustered index creates a key on the columns you indicate and a pointer back to the main table for any columns not part of 
the index.

Data Normalization
The process of restructuring a database in this way is called normalization. There are formal names and definitions for 
different levels of restructuring; the most common are first, second, and third normal form (1NF, 2NF, 3NF). 
In practice, the formal vocabulary tends to be used in academic settings
Data normalization can be a solution for duplicated data, 

CREATE TABLE new_table_name AS SELECT... => create a new table from an existing one

Data update challenges: modify the duplicated information => make the same updates in multiple locations.

Data insertion challenges: when all columns in a table do not depend on the primary key: new data cannot be inserted into the 
table until a primary key is known => theoretically come up with a fake student ID and leave non-relevant columns empty =>
future mistakes and inconsistencies

Data Maintenence
SELECT relname, n_dead_tup, n_live_tup, last_vacuum, last_autovacuum, last_analyze FROM pg_stat_all_tables
=> pg_stat_all_tables is a table that shows statistics about usage statistics for each table in the database.

ANALYZE <tblname>
running ANALYZE with no table name specified will perform an ANALYZE on all tables in the database.

Managing the size of your database tables to keep the tables and indexes in your database small can ensure better 
query performance, more efficient disk utilization, and lower database costs.

pg_size_pretty can be used with the functions above to format a number in bytes as KB, MB, or GB.

pg_size_pretty(pg_total_relation_size('tablename') => get the total size include database table + index size
pg_size_pretty(pg_indexes_size('idxname')) => get the size of a specific idx 
pg_size_pretty(pg_table_size('tablename')) => get the size of a specific table
pg_size_pretty(pg_database_size('databasename')) => get the size of the database
 
When an UPDATE or DELETE is called, PostgreSQL doesn’t physically delete the content from the disk. Instead, the database engine 
marks those rows so that they aren’t returned in user queries. These rows are called dead tuples, and although they aren’t 
referenced in the current version of databases’ tables, they still occupy space on disk and can affect performance.
when UPDATE a table. PostgreSQL creates a new row and marks an “old” row invalid, causing the size of the table to increase

VACUUM <table name> => vacuum a specific table, while a VACUUM statement without a table name will run on the 
entire database.

A plain VACUUM will only clear tables’ dead tuples where possible. Depending on which rows in your table are updated, 
this can clear anywhere between 0 and 100% of dead tuples. If VACUUM cannot clear the dead tuples, PostgreSQL will mark 
the space occupied by dead tuples for reuse when new data is inserted into the table => may not see much of a decrease in space 
before and after a vacuum.